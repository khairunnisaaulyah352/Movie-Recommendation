# -*- coding: utf-8 -*-
"""Untitled8.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1usJMcM_G9FS7ORRaf7iypUbdc6qyenFL

# Data Understanding
"""

!pip install opendatasets

import opendatasets as od

"""Mendownload data yang dibutuhkan"""

od.download('https://www.kaggle.com/datasets/rohan4050/movie-recommendation-data/download?datasetVersionNumber=1')

"""Membaca data yang akan digunakan"""

import pandas as pd

link= pd.read_csv('/content/movie-recommendation-data/ml-latest-small/links.csv')
movies= pd.read_csv('/content/movie-recommendation-data/ml-latest-small/movies.csv')
rating= pd.read_csv('/content/movie-recommendation-data/ml-latest-small/ratings.csv')
tag= pd.read_csv('/content/movie-recommendation-data/ml-latest-small/tags.csv')

movies.info()

link.info()

rating.info()

tag.info()

"""# Data Processing

Menggabungkan Movie
"""

import numpy as np
 
# Menggabungkan seluruh movieID pada kategori movie
movie_all = np.concatenate((
    link.movieId.unique(),
    movies.movieId.unique(),
    rating.movieId.unique(),
    tag.movieId.unique(),
))
 
# Mengurutkan data dan menghapus data yang sama
movie_all = np.sort(np.unique(movie_all))
 
print('Jumlah seluruh data movie berdasarkan movieID: ', len(movie_all))

"""Menggabungkan Seluruh User"""

# Menggabungkan seluruh userId
user_all = np.concatenate((
    rating.userId.unique(),
    tag.userId.unique(),
   
))
 
# Menghapus data yang sama kemudian mengurutkannya
user_all = np.sort(np.unique(user_all)) 
 
print('Jumlah seluruh user: ', len(user_all))

"""Mengetahui Jumlah Rating"""

# Menggabungkan file link, tag, movies ke dalam dataframe movie_info 
movie_info = pd.concat([link, tag, movies])
 
# Menggabungkan dataframe rating dengan movie_info berdasarkan nilai movieId
movie = pd.merge(rating, movie_info , on='movieId', how='left')
movie.head(5)

# Cek missing value dengan fungsi isnull()
movie.isnull().sum()

# Menghitung jumlah rating
movie.groupby('movieId').sum()

"""Menggabungkan Data dengan Fitur Nama movie"""

# Definisikan dataframe rating ke dalam variabel all_movie_rate
all_movie_rate = rating
all_movie_rate.head(5)

# Menggabungkan all movie_rate dengan dataframe moviea berdasarkan movieId
all_movie_name = pd.merge(all_movie_rate, movies[['movieId','title','genres']], on='movieId', how='left')
 
# Print dataframe all_movie_name
all_movie_name.head(5)

"""Menggabungkan Data dengan Fitur Tag"""

# Menggabungkan dataframe genres dengan all_movie_name dan memasukkannya ke dalam variabel all_movie
all_movie = pd.merge(all_movie_name, tag[['movieId','tag']], on='movieId', how='left')
all_movie.head(3)

"""#Data Preparation

Mengatasi Missing Value
"""

all_movie.isnull().sum()

# Membersihkan missing value dengan fungsi dropna()
all_movie_clean = all_movie.dropna()

# Mengecek kembali missing value
all_movie_clean.isnull().sum()

"""Menyamakan Jenis movie"""

# Mengurutkan resto berdasarkan MovieId kemudian memasukkannya ke dalam variabel fix_movie
fix_movie = all_movie_clean.sort_values('movieId', ascending=True)
fix_movie

# Membuat variabel preparation yang berisi dataframe fix_movie 
preparation = fix_movie
preparation.sort_values('movieId')

# Membuang data duplikat pada variabel preparation
preparation = preparation.drop_duplicates('movieId')
preparation

# Mengonversi data series ‘movieId’ menjadi dalam bentuk list
movie_id = preparation['movieId'].tolist()
 
# Mengonversi data series ‘title’ menjadi dalam bentuk list
movie_name = preparation['title'].tolist()
 
# Mengonversi data series ‘genres’ menjadi dalam bentuk list
movie_genre = preparation['genres'].tolist()
 
print(len(movie_id))
print(len(movie_name))
print(len(movie_genre))

# Membuat dictionary untuk data ‘movie_id’, ‘movie_name’, dan ‘movie_genre’
movie_new = pd.DataFrame({
    'id': movie_id,
    'movie_name': movie_name,
    'genre': movie_genre
})
movie_new.head(3)

data = movie_new
data.sample(5)

"""# Model Development dengan Content Based Filtering

TF-IDF Vectorizer
"""

from sklearn.feature_extraction.text import TfidfVectorizer
 
# Inisialisasi TfidfVectorizer
tf = TfidfVectorizer()
 
# Melakukan perhitungan idf pada data genre
tf.fit(data['genre']) 
 
# Mapping array dari fitur index integer ke fitur nama
tf.get_feature_names()

# Melakukan fit lalu ditransformasikan ke bentuk matrix
tfidf_matrix = tf.fit_transform(data['genre'])
 

tfidf_matrix.shape

# Mengubah vektor tf-idf dalam bentuk matriks dengan fungsi todense()
tfidf_matrix.todense()

# Membuat dataframe untuk melihat tf-idf matrix
# Kolom diisi dengan jenis masakan
# Baris diisi dengan nama resto
 
pd.DataFrame(
    tfidf_matrix.todense(), 
    columns=tf.get_feature_names(),
    index=data.movie_name
).sample(22, axis=1).sample(5, axis=0)

"""Mengidentifikasi kesamaan antara satu movie dengan movie lainnya menggunakan cosine similarity"""

from sklearn.metrics.pairwise import cosine_similarity
 
# Menghitung cosine similarity pada matrix tf-idf
cosine_sim = cosine_similarity(tfidf_matrix) 
cosine_sim

# Membuat dataframe dari variabel cosine_sim dengan baris dan kolom berupa nama movie
cosine_sim_df = pd.DataFrame(cosine_sim, index=data['movie_name'], columns=data['movie_name'])
print('Shape:', cosine_sim_df.shape)
 
# Melihat similarity matrix pada setiap movie
cosine_sim_df.sample(5, axis=1).sample(10, axis=0)

"""Mendapatkkan sejumlah movie yang akan direkomendasikan kepada pengguna. teknik yang pakai adalah content based filtering"""

def movie_recommendations(nama_movie, similarity_data=cosine_sim_df, items=data[['movie_name', 'genre']], k=5):
 
    # Mengambil data dengan menggunakan argpartition untuk melakukan partisi secara tidak langsung sepanjang sumbu yang diberikan    
    # Dataframe diubah menjadi numpy
    # Range(start, stop, step)
    index = similarity_data.loc[:,nama_movie].to_numpy().argpartition(
        range(-1, -k, -1))
    
    # Mengambil data dengan similarity terbesar dari index yang ada
    closest = similarity_data.columns[index[-1:-(k+2):-1]]
    
    # Drop nama_movie agar nama movie yang dicari tidak muncul dalam daftar rekomendasi
    closest = closest.drop(nama_movie, errors='ignore')
 
    return pd.DataFrame(closest).merge(items).head(k)

data[data.movie_name.eq('Hancock (2008)')]

#menemukan rekomendasi restoran yang mirip dengan movie hancock
movie_recommendations('Hancock (2008)')